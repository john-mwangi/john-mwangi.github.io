[{"content":"I’m a data analytics specialist with interests in: data science, machine learning, deep learning, statistics, business intelligence, analytics, data engineering, MLOps, software engineering, data governance, and data strategy.\nI have a little over 10 years' experience (as at 2021) and over the time, I\u0026rsquo;ve had the good fortune of doing a very wide variety of projects: started as a consultant with one of the Big Four firms doing technology audits, transitioned to technology advisory focusing on tech strategy development, system implementations, and data analytics, moved to a tier 1 bank doing data governance, moved back to consulting and did a lot of ML and BI projects, then joined a start-up focusing on application of ML and statistics in Behavioural Science.\nI\u0026rsquo;ve worked in all sorts of industries and with all sorts of internal teams - something that I\u0026rsquo;ve come to value over time as I tend to have a better understanding of the perspectives and needs of my colleagues from other functions.\nI\u0026rsquo;m also an entrepreneur in the food, agriculture, and tech spaces ;-)\nQuite the passionate learner - my mantra is NO MORE ZERO DAYS!! It has a great story on Reddit by the way. You should check it out.\n","permalink":"https://data-simplified.dev/aboutme/","summary":"I’m a data analytics specialist with interests in: data science, machine learning, deep learning, statistics, business intelligence, analytics, data engineering, MLOps, software engineering, data governance, and data strategy.\nI have a little over 10 years' experience (as at 2021) and over the time, I\u0026rsquo;ve had the good fortune of doing a very wide variety of projects: started as a consultant with one of the Big Four firms doing technology audits, transitioned to technology advisory focusing on tech strategy development, system implementations, and data analytics, moved to a tier 1 bank doing data governance, moved back to consulting and did a lot of ML and BI projects, then joined a start-up focusing on application of ML and statistics in Behavioural Science.","title":"About Me"},{"content":"We want to test the scaling and unscaling of values.\nlibrary(tidyverse) data_raw \u0026lt;- read_csv(file = \u0026#34;Train.csv\u0026#34;) %\u0026gt;% select(dispatch_day, dispatch_day, order_carrier_type, rider_license_status, rider_amount) %\u0026gt;% head(20) data_raw ## # A tibble: 20 x 4\r## dispatch_day order_carrier_type rider_license_status rider_amount\r## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 27 2 0 1080\r## 2 30 1 0 730\r## 3 14 2 1 490\r## 4 22 2 1 510\r## 5 27 2 0 400\r## 6 22 1 1 400\r## 7 14 1 1 400\r## 8 3 1 0 420\r## 9 18 2 0 420\r## 10 28 2 0 800\r## 11 20 1 0 450\r## 12 28 2 1 400\r## 13 6 2 1 420\r## 14 28 1 0 610\r## 15 12 1 0 450\r## 16 17 1 1 400\r## 17 7 1 1 410\r## 18 20 2 0 400\r## 19 5 1 0 400\r## 20 1 2 0 390\r Scenario 1: Vector or Single Column Note the attributes of this matrix (center, scale) which can be used to unscale the values. When converted to a tibble, these attributes are lost.\ndata_scaled_r \u0026lt;- scale(x = data_raw$rider_amount, center = TRUE, scale = TRUE) data_scaled_r ## [,1]\r## [1,] 3.25329756\r## [2,] 1.29347975\r## [3,] -0.05039532\r## [4,] 0.06159427\r## [5,] -0.55434847\r## [6,] -0.55434847\r## [7,] -0.55434847\r## [8,] -0.44235888\r## [9,] -0.44235888\r## [10,] 1.68544331\r## [11,] -0.27437449\r## [12,] -0.55434847\r## [13,] -0.44235888\r## [14,] 0.62154222\r## [15,] -0.27437449\r## [16,] -0.55434847\r## [17,] -0.49835367\r## [18,] -0.55434847\r## [19,] -0.55434847\r## [20,] -0.61034326\r## attr(,\u0026quot;scaled:center\u0026quot;)\r## [1] 499\r## attr(,\u0026quot;scaled:scale\u0026quot;)\r## [1] 178.588\r These are the values of the scaling and centering used.\nattr(x = data_scaled_r, which = \u0026#34;scaled:center\u0026#34;) ## [1] 499\r attr(x = data_scaled_r, which = \u0026#34;scaled:scale\u0026#34;) ## [1] 178.588\r data_scaled_r * attr(x = data_scaled_r, which = \u0026#34;scaled:scale\u0026#34;) + attr(x = data_scaled_r, which = \u0026#34;scaled:center\u0026#34;) ## [,1]\r## [1,] 1080\r## [2,] 730\r## [3,] 490\r## [4,] 510\r## [5,] 400\r## [6,] 400\r## [7,] 400\r## [8,] 420\r## [9,] 420\r## [10,] 800\r## [11,] 450\r## [12,] 400\r## [13,] 420\r## [14,] 610\r## [15,] 450\r## [16,] 400\r## [17,] 410\r## [18,] 400\r## [19,] 400\r## [20,] 390\r## attr(,\u0026quot;scaled:center\u0026quot;)\r## [1] 499\r## attr(,\u0026quot;scaled:scale\u0026quot;)\r## [1] 178.588\r Scenario 2: Many Columns data_scaled \u0026lt;- scale(x = data_raw, center = TRUE, scale = TRUE) data_scaled ## dispatch_day order_carrier_type rider_license_status rider_amount\r## [1,] 1.02264634 0.9746794 -0.7958224 3.25329756\r## [2,] 1.34389651 -0.9746794 -0.7958224 1.29347975\r## [3,] -0.36943768 0.9746794 1.1937336 -0.05039532\r## [4,] 0.48722941 0.9746794 1.1937336 0.06159427\r## [5,] 1.02264634 0.9746794 -0.7958224 -0.55434847\r## [6,] 0.48722941 -0.9746794 1.1937336 -0.55434847\r## [7,] -0.36943768 -0.9746794 1.1937336 -0.55434847\r## [8,] -1.54735494 -0.9746794 -0.7958224 -0.44235888\r## [9,] 0.05889586 0.9746794 -0.7958224 -0.44235888\r## [10,] 1.12972973 0.9746794 -0.7958224 1.68544331\r## [11,] 0.27306264 -0.9746794 -0.7958224 -0.27437449\r## [12,] 1.12972973 0.9746794 1.1937336 -0.55434847\r## [13,] -1.22610478 0.9746794 1.1937336 -0.44235888\r## [14,] 1.12972973 -0.9746794 -0.7958224 0.62154222\r## [15,] -0.58360446 -0.9746794 -0.7958224 -0.27437449\r## [16,] -0.04818752 -0.9746794 1.1937336 -0.55434847\r## [17,] -1.11902139 -0.9746794 1.1937336 -0.49835367\r## [18,] 0.27306264 0.9746794 -0.7958224 -0.55434847\r## [19,] -1.33318817 -0.9746794 -0.7958224 -0.55434847\r## [20,] -1.76152171 0.9746794 -0.7958224 -0.61034326\r## attr(,\u0026quot;scaled:center\u0026quot;)\r## dispatch_day order_carrier_type rider_license_status ## 17.45 1.50 0.40 ## rider_amount ## 499.00 ## attr(,\u0026quot;scaled:scale\u0026quot;)\r## dispatch_day order_carrier_type rider_license_status ## 9.3385167 0.5129892 0.5026247 ## rider_amount ## 178.5880293\r scale \u0026lt;- attr(data_scaled, which = \u0026#34;scaled:scale\u0026#34;) center \u0026lt;- attr(data_scaled, which = \u0026#34;scaled:center\u0026#34;) apply(X = data_scaled, MARGIN = 1, FUN = function(x) x * scale + center) %\u0026gt;% t() %\u0026gt;% as_tibble() ## # A tibble: 20 x 4\r## dispatch_day order_carrier_type rider_license_status rider_amount\r## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 27 2 0 1080\r## 2 30 1 0 730\r## 3 14 2 1 490\r## 4 22 2 1 510\r## 5 27 2 0 400\r## 6 22 1 1 400\r## 7 14 1 1 400\r## 8 3 1 0 420\r## 9 18 2 0 420\r## 10 28 2 0 800\r## 11 20 1 0 450\r## 12 28 2 1 400\r## 13 6 2 1 420\r## 14 28 1 0 610\r## 15 12 1 0 450\r## 16 17 1 1 400\r## 17 7.00 1 1 410\r## 18 20 2 0 400\r## 19 5 1 0 400\r## 20 1 2 0 390\r ","permalink":"https://data-simplified.dev/posts/scale-unscale/","summary":"A demo of how to scale then unscale data when training an ML model.","title":"Scaling and Unscaling Data"}]